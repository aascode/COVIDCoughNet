{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!conda install -y -c conda-forge librosa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install vit-pytorch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport librosa\ndef get_melspectrogram_db(file_path, sr=22937, n_fft=2048, hop_length=512, n_mels=224, fmin=20, fmax=8300, top_db=80):\n    wav,sr = librosa.load(file_path,sr=sr)\n    if wav.shape[0]<5*sr:\n        wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n    else:\n        wav=wav[:5*sr]\n    spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,\n              hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n    spec_db=librosa.power_to_db(spec,top_db=top_db)\n    return spec_db","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spec_to_image(spec, eps=1e-6):\n    mean = spec.mean()\n    std = spec.std()\n    spec_norm = (spec - mean) / (std + eps)\n    spec_min, spec_max = spec_norm.min(), spec_norm.max()\n    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n    spec_scaled = spec_scaled.astype(np.uint8)\n    return spec_scaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Initialization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import data from cough dataset\nimport os\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nPOSITIVE_FOLDER = \"pos\"\nNEGATIVE_FOLDER = \"neg\"\n\nROOT = \"/kaggle/input/coughnetwithwavegangen\"\n\nclass CoughDataSet(Dataset):\n    def __init__(self, root=ROOT, dataset_type=\"train\"):\n        self.root = root\n        positive_coughs = []\n        negative_coughs = []\n        for entry in os.scandir(os.path.join(self.root, os.path.join(dataset_type, POSITIVE_FOLDER))):\n            if entry.is_file():\n                positive_coughs.append(entry.path)\n        for entry in os.scandir(os.path.join(self.root, os.path.join(dataset_type, NEGATIVE_FOLDER))):\n            if entry.is_file():\n                negative_coughs.append(entry.path)\n        data = [] # will contain tuples\n        labels = []\n        for filename in positive_coughs:\n            # Load image\n            mel_db = get_melspectrogram_db(filename)\n            # Transform image using spec_to_image and get_melspectrogram_db\n            spec_img = spec_to_image(mel_db)\n            # Adjust for densenet required 3-channels\n            spec_img_three_channel = np.repeat(spec_img[np.newaxis,...], 3, 0)\n            data.append(spec_img_three_channel)\n            labels.append(0)\n        for filename in negative_coughs:\n            # Load image\n            mel_db = get_melspectrogram_db(filename)\n            # Transform image using spec_to_image and get_melspectrogram_db\n            spec_img = spec_to_image(mel_db)\n            # Adjust for densenet required 3-channels\n            spec_img_three_channel = np.repeat(spec_img[np.newaxis,...], 3, 0)\n            data.append(spec_img_three_channel)\n            labels.append(1)\n        self.data = data\n        self.labels = labels\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, index):\n        return self.data[index], self.labels[index]\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_data = CoughDataSet(dataset_type=\"test\")\n# test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n\n# test_iter = iter(test_loader)\n# batch = iter(test_iter)\n# for x, y in batch:\n#     print(x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = CoughDataSet()\ntest_data = CoughDataSet(dataset_type=\"test\")\nvalid_data = CoughDataSet(dataset_type=\"val\")\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_data, batch_size=32, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(test_data, batch_size=32, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initialize Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"from ignite.metrics import Accuracy, Precision, Recall\nfrom ignite.contrib.metrics import RocCurve\n\n# Setup Training Metrics\ntraining_metrics = [Accuracy()]\n\nfor metric in training_metrics:\n    metric.reset()\n\n# Setup Validation Metrics\nmetrics = [Accuracy(), Precision(average=False), Recall(average=False)]\n\n# Add F1 Score as a Metric\nF1 = (metrics[1] * metrics[2] * 2 / (metrics[1] + metrics[2])).mean()\nmetrics.append(F1)\n\nfor metric in metrics:\n    metric.reset()\n\n# Setup Test Metrics\ntest_metrics = [Accuracy(), Precision(average=False), Recall(average=False)]\n\n# Add F1 Score as a Metric\nF1 = (test_metrics[1] * test_metrics[2] * 2 / (test_metrics[1] + test_metrics[2])).mean()\ntest_metrics.append(F1)\n\nfor metric in test_metrics:\n    metric.reset()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tensorboard Logging"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\nsummary_writer = SummaryWriter(\"/kaggle/working/bleh_waveganv2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Initialization"},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport pytorch_lightning as pl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Constant Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 3e-4\nstart_epoch = 1\nepochs = 100\nloss_fn = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Device"},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device('cuda:0')\n    print(device)\nelse:\n    device=torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup Transformer"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import optim\nfrom vit_pytorch import ViT\n\nmodel = ViT(\n    image_size = 224,\n    patch_size = 32,\n    num_classes = 2,\n    dim = 128,\n    depth = 12,\n    heads = 8,\n    mlp_dim = 128\n).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\nloss_function = torch.nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup Training Iteration for Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss_history = []\ntest_loss_history = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom tqdm import tqdm\n\nstart_time = time.time()\nfor epoch in range(start_epoch, epochs):\n    print('Epoch:', epoch)\n    \n    # Initialize training \n    model.train()\n    batch_losses=[]\n    train_accuracy = training_metrics[0]\n    \n    for data, label in tqdm(train_loader):\n        data = data.to(device, dtype=torch.float32)\n        label = label.to(device, dtype=torch.long)\n        \n        optimizer.zero_grad()\n\n        output = model(data)\n        loss = loss_fn(output, label)\n        \n        train_accuracy.update((output, label))\n\n        loss.backward()\n        \n        batch_losses.append(loss.item())\n        optimizer.step()\n    train_loss_history.append(batch_losses)\n    \n    # Add Training Accuracy to Summary\n    computed_train_accuracy = train_accuracy.compute()\n    summary_writer.add_scalar(\"Training Accuracy\", computed_train_accuracy, epoch)\n    print(f'Epoch - {epoch} Train-Loss : {np.mean(train_loss_history[-1])} Train-Accuracy: {computed_train_accuracy}')\n    train_accuracy.reset() # reset for next epoch's use\n    \n    # Perform validation on epoch\n    model.eval()\n    with torch.no_grad():\n        batch_losses = []\n        for data, label in valid_loader:\n            data = data.to(device, dtype=torch.float32)\n            label = label.to(device, dtype=torch.long)\n\n            val_output = model(data)\n            val_loss = loss_fn(val_output, label)\n            \n            batch_losses.append(val_loss.item())\n            \n            # Calculate metrics here on validation data\n            for metric in metrics:\n                metric.update((val_output, label))\n        test_loss_history.append(batch_losses)\n    \n    # Finally add metrics for validation\n    for metric in metrics:\n        metric_name = metric.__class__.__name__\n        computed_metric = metric.compute()\n        if (torch.is_tensor(computed_metric) and len(computed_metric.size()) > 0):\n            # Must iterate because this is a tensor\n            for idx, row in enumerate(computed_metric):\n                summary_writer.add_scalar(metric_name + f' of {idx}', row, epoch)\n        else:\n            # Add Metric to Summary\n            summary_writer.add_scalar(metric_name, computed_metric, epoch)\n        print(\"Validation {} is {}\".format(metric_name, computed_metric))\n        \n    # Finally reset metrics for next iteration\n    for metric in metrics:\n        metric.reset()\n    \n    summary_writer.flush()\n    \n    # Check Test Results\n    total = 0\n    correct = 0\n    with torch.no_grad():\n        for data, label in test_loader:\n            data = data.to(device, dtype=torch.float32)\n            label = label.to(device, dtype=torch.long)\n\n            test_output = model(data)\n            _, predicted = torch.max(test_output, 1)\n            for metric in test_metrics:\n                metric.update((predicted, label))\n\n    for metric in test_metrics:\n        metric_name = metric.__class__.__name__\n        computed_metric = metric.compute()\n        if (torch.is_tensor(computed_metric) and len(computed_metric.size()) > 0):\n            # Must iterate because this is a tensor\n            for idx, row in enumerate(computed_metric):\n                summary_writer.add_scalar(metric_name + f' of {idx}', row, epoch)\n        else:\n            # Add Metric to Summary\n            summary_writer.add_scalar(metric_name, computed_metric, epoch)\n        print(\"Test {} is {}\".format(metric_name, computed_metric))\n\n    # Finally reset metrics for next iteration\n    for metric in test_metrics:\n        metric.reset()\n\nprint('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !mkdir /kaggle/working/checkpoints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, _ in os.walk(\"/kaggle\"):\n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/working/checkpoints/{}_{}.pth'.format(\"nonwavegan\", epoch), 'wb') as f:\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, f)\ncheckpoint = torch.load(f'/kaggle/working/checkpoints/{\"nonwavegan\"}_{epoch}.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_writer.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -r checkpoints.zip /kaggle/working/checkpoints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks('/kaggle/working/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = 0\ncorrect = 0\n\nmodel.eval()\nwith torch.no_grad():\n    for data, label in test_loader:\n        data = data.to(device, dtype=torch.float32)\n        label = label.to(device, dtype=torch.long)\n\n        test_output = model(data)\n        _, predicted = torch.max(test_output, 1)\n        print(predicted)\n        print(label)\n\n        total += len(label)\n        correct += (predicted == label).sum().item()\nprint(f\"Test Accuracy: {correct / total}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
